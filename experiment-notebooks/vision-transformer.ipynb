{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_heads=2,key_dim=8,attention_axes=(2,3,4)):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim,attention_axes=attention_axes)\n",
    "    def call(self,x):\n",
    "        return self.mha(query=x, key=x, value=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.layers.Layer):\n",
    "    def __init__(self,input_dims, output_dims, mlp_ratio=1):\n",
    "        super().__init__()\n",
    "        self.input_dims=input_dims\n",
    "        self.output_dims=output_dims\n",
    "        self.mlp_ratio=mlp_ratio\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        neuron_count=int(self.mlp_ratio * input_shape[-1])\n",
    "        self.dense1=tf.keras.layers.Dense(neuron_count,activation='relu')\n",
    "        self.dense2=tf.keras.layers.Dense(self.output_dims,activation='relu')\n",
    "        \n",
    "    def call(self,x):\n",
    "        x=self.dense1(x)\n",
    "        x=self.dense2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_window_partition(x, window_size):\n",
    "    B, T, H, W, C = x.shape\n",
    "    windows = []\n",
    "\n",
    "    for t in range(T // window_size[0]):\n",
    "        for h in range(H // window_size[1]):\n",
    "            for w in range(W // window_size[2]):\n",
    "                temp = x[:, t * window_size[0]:(t + 1) * window_size[0],\n",
    "                         h * window_size[1]:(h + 1) * window_size[1],\n",
    "                         w * window_size[2]:(w + 1) * window_size[2]]\n",
    "                windows.append(temp)\n",
    "\n",
    "    \n",
    "    windows = tf.stack(windows)\n",
    "    return windows\n",
    "\n",
    "def reverse_window_partition(windows, original_shape, window_size):\n",
    "    B, T, H, W, C = original_shape\n",
    "\n",
    "    output_shape = (B, T, H, W, C)\n",
    "\n",
    "    video = np.zeros(output_shape, dtype=np.float32)\n",
    "    window_idx = 0\n",
    "\n",
    "    for t in range(T // window_size[0]):\n",
    "        for h in range(H // window_size[1]):\n",
    "            for w in range(W // window_size[2]):\n",
    "                temp = windows[window_idx]\n",
    "                video[:, t * window_size[0]:(t + 1) * window_size[0],\n",
    "                      h * window_size[1]:(h + 1) * window_size[1],\n",
    "                      w * window_size[2]:(w + 1) * window_size[2], :] = temp\n",
    "                window_idx += 1\n",
    "\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 1, 4, 4, 3) (None, 32, 2, 1, 4, 4, 1, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "x=tf.zeros(( 32,1, 4, 4, 3))\n",
    "\n",
    "layer = tf.keras.layers.MultiHeadAttention(\n",
    "    num_heads=2, key_dim=2,attention_axes=(2,3,4))\n",
    "input_tensor = tf.keras.Input(shape=x.shape)\n",
    "output_tensor,scores = layer(input_tensor, input_tensor,return_attention_scores=True)\n",
    "print(output_tensor.shape, scores.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowMSA(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_heads=2,key_dim=8):\n",
    "        super().__init__()\n",
    "        self.num_heads=num_heads\n",
    "        self.key_dim=key_dim\n",
    "\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.layer_norm1=tf.keras.layers.LayerNormalization()\n",
    "        self.layer_norm2=tf.keras.layers.LayerNormalization()\n",
    "        self.spatial_msa=BaseAttention(self.num_heads, self.key_dim)\n",
    "        self.temporal_msa=BaseAttention(self.num_heads, self.key_dim)\n",
    "        self.mlp=MLP(input_shape[-1],input_shape[-1])\n",
    "        \n",
    "    def call(self,x):\n",
    "        B,T,H,W,C=x.shape\n",
    "        MH,MW=H//16,W//24\n",
    "\n",
    "        self.temporal_window=(T,1,1)\n",
    "        self.spatial_window=(1,MH,MW)\n",
    "        \n",
    "        \n",
    "        x=self.layer_norm1(x)\n",
    "        windows=normal_window_partition(x,self.spatial_window)\n",
    "        \n",
    "        windows=tf.transpose(windows, (1,0,2,3,4,5)) \n",
    "        x=self.spatial_msa(windows)\n",
    "        x=tf.transpose(x, (1,0,2,3,4,5))\n",
    "        \n",
    "\n",
    "        x=reverse_window_partition(x,(B,T,H,W,C), self.spatial_window )\n",
    "        windows=normal_window_partition(x, self.temporal_window)\n",
    "        windows=tf.transpose(windows, (1,0,2,3,4,5))\n",
    "        x=self.temporal_msa(windows)\n",
    "        x=tf.transpose(x, (1,0,2,3,4,5))\n",
    "        \n",
    "        x=reverse_window_partition(x,(B,T,H,W,C),self.temporal_window)\n",
    "        x=self.layer_norm2(x)\n",
    "        x=self.mlp(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_window_partition(x,window_size):\n",
    "    B,T,H,W,C=x.shape\n",
    "    window_size =[4*i for i in window_size]\n",
    "    print(window_size)\n",
    "    corner_windows=[]\n",
    "    corner_windows.append(x[:,:,tf.newaxis,:window_size[0],:window_size[1]])\n",
    "    corner_windows.append(x[:,:,tf.newaxis,:window_size[0],-window_size[1]:])\n",
    "    corner_windows.append(x[:,:,tf.newaxis,-window_size[0]:,:window_size[1]])\n",
    "    corner_windows.append(x[:,:,tf.newaxis,-window_size[0]:,-window_size[1]:])\n",
    "    \n",
    "    \n",
    "    side_windows=[]\n",
    "    side_windows.append(x[:,:,tf.newaxis,:window_size[0],window_size[1]:-window_size[1]])\n",
    "    side_windows.append(x[:,:,tf.newaxis,window_size[0]:-window_size[0],:window_size[1]])\n",
    "    side_windows.append(x[:,:,tf.newaxis,window_size[0]:-window_size[0],-window_size[1]:])\n",
    "    side_windows.append(x[:,:,tf.newaxis,-window_size[0]:,window_size[1]:-window_size[1]])\n",
    "    \n",
    "    middle_window=x[:,:,tf.newaxis, window_size[0]:-window_size[0],window_size[1]:-window_size[1]]\n",
    "\n",
    "    s=tf.concat(corner_windows,axis=1)\n",
    "\n",
    "    \n",
    "    return tf.concat(corner_windows,axis=1),tf.concat([side_windows[0],side_windows[-1]],axis=1) , tf.concat([side_windows[1],side_windows[-2]],axis=1) ,middle_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_shifted_window_partition(x,orginal_shape,window_size):\n",
    "    B,T,H,W,C=orginal_shape\n",
    "    window_size =[4*i for i in window_size]\n",
    "    corner_windows,top_bottom,left_right,middle=x\n",
    "    y=np.zeros((B,T,H,W,C),dtype=np.float32)\n",
    "    \n",
    "    corner_windows=tf.squeeze(corner_windows)\n",
    "    s=corner_windows.shape[1]//4\n",
    "    y[:,:,:window_size[0],:window_size[1]]=corner_windows[:,:s]\n",
    "    y[:,:,:window_size[0],-window_size[1]:]=corner_windows[:,s:2*s]\n",
    "    y[:,:,-window_size[0]:,:window_size[1]]=corner_windows[:,2*s:-s]\n",
    "    y[:,:,-window_size[0]:,-window_size[1]:]=corner_windows[:,-s:]\n",
    "    \n",
    "    \n",
    "    left_right=tf.squeeze(left_right)\n",
    "    s=left_right.shape[1]//2\n",
    "    y[:,:,window_size[0]:-window_size[0],:window_size[1]]=left_right[:,:s]\n",
    "    y[:,:,window_size[0]:-window_size[0],-window_size[1]:]=left_right[:,s:]\n",
    "    \n",
    "    \n",
    "    top_bottom=tf.squeeze(top_bottom)\n",
    "    s=top_bottom.shape[1]//2 \n",
    "    y[:,:,:window_size[0],window_size[1]:-window_size[1]]= top_bottom[:,:s]\n",
    "    y[:,:,-window_size[0]:,window_size[1]:-window_size[1]]= top_bottom[:,s:]\n",
    "    \n",
    "    middle=tf.squeeze(middle)\n",
    "    y[:,:, window_size[0]:-window_size[0],window_size[1]:-window_size[1]]=middle\n",
    "    \n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 16]\n",
      "(10, 16, 1, 16, 16, 3)\n",
      "(16, 10, 1, 16, 16, 3)\n",
      "(8, 10, 1, 16, 352, 3)\n",
      "(8, 10, 1, 124, 16, 3)\n",
      "(4, 10, 1, 124, 352, 3)\n"
     ]
    }
   ],
   "source": [
    "x=tf.random.uniform((10,4,156,384,3))\n",
    "\n",
    "c=shifted_window_partition(x,(4,4))\n",
    "print(c[0].shape)\n",
    "\n",
    "cc=[]\n",
    "for i in c:\n",
    "    i=tf.transpose(i,(1,0,2,3,4,5))\n",
    "    print(i.shape)\n",
    "    cc.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftedWindowMSA(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_heads=2,key_dim=8):\n",
    "        super().__init__()\n",
    "        self.num_heads=num_heads\n",
    "        self.key_dim=key_dim\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.layer_norm1=tf.keras.layers.LayerNormalization()\n",
    "        self.layer_norm2=tf.keras.layers.LayerNormalization()\n",
    "        self.spatial_msa=BaseAttention(self.num_heads, self.key_dim)\n",
    "        self.temporal_msa=BaseAttention(self.num_heads, self.key_dim)\n",
    "        self.mlp=MLP(input_shape[-1],input_shape[-1])\n",
    "        \n",
    "        \n",
    "    def call(self,x):\n",
    "        B,T,H,W,C=x.shape\n",
    "        MH,MW=H//16,W//24\n",
    "\n",
    "        x=self.layer_norm1(x)\n",
    "\n",
    "        \n",
    "        x=shifted_window_partition(x,(MH,MW))\n",
    "        all_windows=[]\n",
    "        for window_blocks in x:\n",
    "            window_blocks=self.spatial_msa(window_blocks)\n",
    "            all_windows.append(window_blocks)\n",
    "        \n",
    "        x=reverse_shifted_window_partition(all_windows,(B,T,H,W,C),(MH,MW)) \n",
    "        windows=normal_window_partition(x,(T,1,1))\n",
    "        \n",
    "        windows=tf.transpose(windows, (1,0,2,3,4,5))\n",
    "        x=self.spatial_msa(windows)\n",
    "        x=tf.transpose(x, (1,0,2,3,4,5))\n",
    "        \n",
    "        x=reverse_window_partition(x,(B,T,H,W,C),(T,1,1))\n",
    "        x=self.layer_norm2(x)\n",
    "        x=self.mlp(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SepSTSBock(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.window_msa=WindowMSA(num_heads=1, key_dim=1)\n",
    "        self.shifted_window_msa=ShiftedWindowMSA(num_heads=1, key_dim=1)\n",
    "        self.conv=tf.keras.layers.Conv3D(1,kernel_size=(3,3,3),padding='same')\n",
    "        \n",
    "\n",
    "    def call(self,x):\n",
    "        x=self.conv(x)\n",
    "        s=time.time()\n",
    "        x=self.window_msa(x)\n",
    "        e=time.time()\n",
    "        print('for W MSA: ',e-s)\n",
    "        x=self.shifted_window_msa(x)\n",
    "        print('for SW MSA: ',time.time()-e)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.random.uniform((10,4,64,96,3))\n",
    "layer=SepSTSBock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model=8):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.embeddings = tf.keras.layers.Dense(self.d_model , activation='relu')\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.embeddings(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DeepEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self,nf):\n",
    "        super().__init__()\n",
    "        self.nf=nf\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.down0 = tf.keras.layers.Conv3D(filters=self.nf[-1], kernel_size=(1, 2, 2), strides=(1, 2, 2), padding='same')\n",
    "        self.down1 = tf.keras.layers.Conv3D(filters=self.nf[-2], kernel_size=(1, 2, 2), strides=(1, 2, 2), padding='same')\n",
    "        self.down2 = tf.keras.layers.Conv3D(filters=self.nf[-3], kernel_size=(1, 2, 2), strides=(1, 2, 2), padding='same')\n",
    "        self.down3 = tf.keras.layers.Conv3D(filters=self.nf[-4], kernel_size=(1, 2, 2), strides=(1, 2, 2), padding='same')\n",
    "        \n",
    "        self.sts0=SepSTSBock()\n",
    "        self.sts1=SepSTSBock()\n",
    "        self.sts2=SepSTSBock()\n",
    "        self.sts3=SepSTSBock()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        x0=self.down0(x)\n",
    "\n",
    "        \n",
    "        x0=self.sts0(x0)\n",
    "        \n",
    "        x0=tf.squeeze(x0)\n",
    "        x1=self.down1(x0)\n",
    "        x1=self.sts1(x1)\n",
    "        \n",
    "        x1=tf.squeeze(x1)\n",
    "        x2=self.down2(x1)\n",
    "        x2=self.sts2(x2)\n",
    "        \n",
    "        x2=tf.squeeze(x2)\n",
    "        x3=self.down3(x2)\n",
    "        x3=self.sts3(x3)\n",
    "        \n",
    "        return x0,x1,x2,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.nf=[1, 1, 1, 1]\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.shallow=ShallowEmbedding()\n",
    "        self.deep=DeepEmbedding(self.nf)\n",
    "        \n",
    "    def call(self,x):\n",
    "        x=self.shallow(x)\n",
    "        x=self.deep(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.upsample0=tf.keras.layers.UpSampling3D(size=2)\n",
    "        self.upsample1=tf.keras.layers.UpSampling3D(size=2)\n",
    "        self.upsample2=tf.keras.layers.UpSampling3D(size=2)\n",
    "        self.upsample3=tf.keras.layers.UpSampling3D(size=2)\n",
    "        self.add=tf.keras.layers.Add()\n",
    "    \n",
    "    def call(self,x):\n",
    "        x0,x1,x2,x3=x\n",
    "        \n",
    "        y0=self.upsample0(x3)\n",
    "        y0=self.add(y0,x2)\n",
    "        \n",
    "        y1=self.upsample0(y0)\n",
    "        y1=self.add(y1,x1)\n",
    "        \n",
    "        y2=self.upsample0(y1)\n",
    "        y2=self.add(y2,x0)\n",
    "\n",
    "        y3=self.upsample0(y2)\n",
    "        \n",
    "        return y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.encoder=Encoder()\n",
    "        self.decoder=Decoder()\n",
    "        super(Transformer, self).build(input_shape)\n",
    "        \n",
    "    def call(self,x):\n",
    "        encoder_outputs=self.encoder(x)\n",
    "        x=self.decoder(encoder_outputs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tarad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
